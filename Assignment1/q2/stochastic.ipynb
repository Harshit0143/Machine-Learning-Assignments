{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_CNT = 1000000\n",
    "x = np.ones((3 , SAMPLE_CNT) , dtype = np.float64)\n",
    "\n",
    "x[1] = np.random.normal(3, 2 , SAMPLE_CNT)\n",
    "x[2] = np.random.normal(-1, 2 , SAMPLE_CNT)\n",
    "noise = np.random.normal(0, np.sqrt(2), SAMPLE_CNT)\n",
    "THETA_T = np.array([3 , 1 , 2] , dtype = np.float64)\n",
    "y = THETA_T[0] + x[1] * THETA_T[1]  + x[2] * THETA_T[2] + noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on training data using original θ = [3 1 2]: 0.9994929487551175\n",
      "On training data:\n",
      "Batch size: 1\n",
      "Number of batches: 1000000\n",
      "Time taken: 60.88397288322449 seconds\n",
      "Complete data traversed: 3 times\n",
      "Number of iterations: 3000000\n",
      "Final 0 value obtained: [2.93867568 1.01575906 2.0109744 ]\n",
      "Final J(0), averages over last epoch: 1.0092811255477503\n"
     ]
    }
   ],
   "source": [
    "\n",
    "descent_theta0 = []\n",
    "descent_theta1 = []\n",
    "descent_theta2 = []\n",
    "descent_J = []\n",
    "\n",
    "\n",
    "def show_cost_plot(save_name):\n",
    "    plt.title(\"Cost Function variation with each iteration\")\n",
    "    plt.xlabel(\"Number of iterations\")\n",
    "    plt.ylabel(\"Cost function: J(θ)\")\n",
    "    plt.plot(np.arange(0, len(descent_J) , 1), descent_J)\n",
    "    plt.savefig(\"./Assignment/data/q2/\" + save_name ,  dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def plot_theta_3D(save_name):\n",
    "    \n",
    "    coordinate_system = plt.figure()\n",
    "    axes = coordinate_system.add_subplot(111, projection = \"3d\")\n",
    "\n",
    "    axes.scatter(descent_theta0, descent_theta1, descent_theta2, color = \"red\", marker = \".\", s = 2 , label = \"θ during descent\")\n",
    "    axes.plot(descent_theta0, descent_theta1, descent_theta2, linewidth = 1, color = \"blue\", label = \"direstion of θ change\")\n",
    "\n",
    "    axes.plot(descent_theta0 , descent_theta1 , descent_theta2 , color = \"red\", marker = \".\", label = \"θ during descent\")\n",
    "    axes.set_title(\"θ after each iterations\")\n",
    "    axes.set_xlabel(\"θ(0)\")\n",
    "    axes.set_ylabel(\"θ(1)\")\n",
    "    axes.set_zlabel('θ(2)')\n",
    "    axes.legend()\n",
    "    plt.savefig(\"./Assignment/data/q2/\" + save_name ,  dpi = 300)\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def stochastic_gradient_descent(BATCH_SIZE, x , y , alpha = 0.001 , tolerance = 0.0000000000000000001):\n",
    "    global descent_theta0 , descent_theta1 , descent_theta2 , descent_J\n",
    "    # MAX_EPOCHES = 40000\n",
    "    MAX_EPOCHES = 100000  \n",
    "    BATCH_CNT = len(y) // BATCH_SIZE\n",
    "    batches =   [x[: , i * BATCH_SIZE  : (i + 1) * BATCH_SIZE] for i in range (BATCH_CNT)]\n",
    "    batches_Y = [y[i * BATCH_SIZE  : (i + 1) * BATCH_SIZE] for i in range (BATCH_CNT)] \n",
    "    epoch = 0\n",
    "    J_curr = None\n",
    "    J_prev_avg = None\n",
    "    J_curr_avg = 0\n",
    "    thetaT = np.zeros(3 , dtype = np.float64)\n",
    "    while (epoch < MAX_EPOCHES):\n",
    "        for i in range (BATCH_CNT):\n",
    "            coeff = batches_Y[i] - np.matmul(thetaT , batches[i])\n",
    "            del_thetaT = np.matmul(batches[i] , coeff) / BATCH_SIZE\n",
    "            thetaT  +=  alpha * del_thetaT\n",
    "            \n",
    "            J_curr =  np.sum(coeff ** 2) / (2 * BATCH_SIZE)\n",
    "            J_curr_avg = (J_curr_avg * i + J_curr) / (i + 1)\n",
    "            \n",
    "      \n",
    "            descent_theta0.append(thetaT[0])\n",
    "            descent_theta1.append(thetaT[1])\n",
    "            descent_theta2.append(thetaT[2])\n",
    "            descent_J.append(J_curr)\n",
    "        epoch += 1 \n",
    "\n",
    "          \n",
    "        if (J_prev_avg !=  None and abs(J_prev_avg - J_curr_avg) < tolerance):\n",
    "            break\n",
    "        J_prev_avg = J_curr_avg\n",
    "\n",
    "    return thetaT , J_curr_avg, epoch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cost_function(x , y, thetaT__):\n",
    "    coeff = y - np.matmul(thetaT__ , x)\n",
    "    J =  np.sum(coeff ** 2) / (2 * len(y))\n",
    "    return J\n",
    "\n",
    "\n",
    "BATCH_SIZES = [1 , 100 , 10000 , 1000000]\n",
    "theta_learnt = []\n",
    "\n",
    "\n",
    "\n",
    "print(\"Error on training data using original θ = [3 1 2]:\" , cost_function(x , y , THETA_T))\n",
    "print(\"On training data:\")\n",
    "for batch_size in (BATCH_SIZES):\n",
    "    t_st = time.time()\n",
    "    thetaT , J_final , epoch = stochastic_gradient_descent(batch_size , x , y)\n",
    "    t_end = time.time()\n",
    "    print(\"Batch size:\" , batch_size)\n",
    "    print(\"Number of batches:\", SAMPLE_CNT // batch_size)\n",
    "    print(\"Time taken:\" , t_end - t_st , \"seconds\")\n",
    "    print(\"Complete data traversed:\", epoch , \"times\")\n",
    "    print(\"Number of iterations:\", epoch * (SAMPLE_CNT // batch_size))\n",
    "    print(\"Final 0 value obtained:\" , thetaT)\n",
    "    print(\"Final J(0), averages over last epoch:\" , J_final)\n",
    "    theta_learnt.append(thetaT)\n",
    "    plot_theta_3D(\"D3_curve_bsize\" + str(batch_size))\n",
    "    show_cost_plot(\"cost_itr_bsize\" + str(batch_size))\n",
    "    print()\n",
    "    descent_theta0 = []\n",
    "    descent_theta1 = []\n",
    "    descent_theta2 = []\n",
    "    descent_J = []\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on testing data using original θ = [3 1 2|]: 0.9829469215\n",
      "On testing data data:\n",
      "Batch size: 1\n",
      "Number of batches: 1000000\n",
      "theta: [3.04305381 0.98018918 2.04124854]\n",
      "Error value using learned 0: 1.0842688473998006\n",
      "\n",
      "Batch size: 100\n",
      "Number of batches: 10000\n",
      "theta: [3.00324736 0.99868254 2.00283175]\n",
      "Error value using learned 0: 0.983112794136199\n",
      "\n",
      "Batch size: 10000\n",
      "Number of batches: 100\n",
      "theta: [3.00205064 0.99928366 2.00016621]\n",
      "Error value using learned 0: 0.9829835949055766\n",
      "\n",
      "Batch size: 1000000\n",
      "Number of batches: 1\n",
      "theta: [3.00208445 0.99947265 2.00003254]\n",
      "Error value using learned 0: 0.9829773734489335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "Q2_PATH = \"Assignment/data/q2/q2test.csv\"\n",
    "\n",
    "            \n",
    "\n",
    "def read_input_q2(): \n",
    "    data = np.loadtxt(Q2_PATH , skiprows = 1 ,  dtype = np.float64  , delimiter = \",\")\n",
    "    x = np.ones((3 , len(data)) , dtype = np.float64)\n",
    "    data = data.T\n",
    "    x[1 : 3] = data[0 : 2]    \n",
    "    y = data[2]\n",
    "    return x , y\n",
    "\n",
    "x , y = read_input_q2()\n",
    "\n",
    "\n",
    "def cost_function__(x , y, thetaT__):\n",
    "    coeff = y - np.matmul(thetaT__ , x)\n",
    "    J =  np.sum(coeff ** 2) / (2 * len(y))\n",
    "    return J\n",
    "\n",
    "\n",
    "print(\"Error on testing data using original θ = [3 1 2|]:\" , cost_function__(x , y , THETA_T))\n",
    "print(\"On testing data data:\")\n",
    "for i in range(len(theta_learnt)):\n",
    "    print(\"Batch size:\" , BATCH_SIZES[i])\n",
    "    print(\"Number of batches:\", SAMPLE_CNT // BATCH_SIZES[i])\n",
    "    print(\"theta:\"  , theta_learnt[i])\n",
    "    print(\"Error value using learned 0:\", cost_function__(x , y , theta_learnt[i]))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
